---
title: "N741 Spring 2018 - Homework 6"
subtitle:  "Homework 6"
author: "Rosemary Kinuthia"
date: "April 2, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven)
```

```{r}
helpdata <- haven::read_spss("helpmkh.sav")

```

```{r}
sub1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd)
```

```{r}
# create a function to get the label
# label output from the attributes() function
getlabel <- function(x) attributes(x)$label
# getlabel(sub1$age)
```

```{r}
# load libraries and dataset
library(tidyverse)
library(haven)
helpdata <- haven::read_spss("helpmkh.sav")
```

```{r}
# choose variables for Homework 6
h1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd)
```

```{r}
# add dichotomous variable
# to indicate depression for
# people with CESD scores >= 16

h1 <- h1 %>%
  mutate(cesd_gte16 = cesd >= 16)
```

```{r}
# change cesd_gte16 LOGIC variable type
# to numeric coded 1=TRUE and 0=FALSE

h1$cesd_gte16 <- as.numeric(h1$cesd_gte16)
```

```{r}
# check final data subset h1
summary(h1)
```


## Homework 6 Tasks
1. [Model 1] Run a simple linear regression (`lm()`) for `cesd` using the `mcs` variable, which is the mental component quality of life score from the SF36.

```{r}
#linear regression of CESD using MCS
Model1 <- lm(cesd~mcs, data=h1)
summary(Model1)
```

2. Write the equation of the final fitted model (i.e. what is the intercept and the slope)? Write a sentence describing the model results (interpret the intercept and slope). _NOTE: The `mcs` values range form 0 to 100 where the population norm for "normal mental health quality of life" is considered to be a 50. If you score higher than 50 on the `mcs` you have mental health better than the population and visa versa - if your `mcs` scores are less than 50 then your mental health is considered to be worse than the population norm._

```{r}
#Y= 53.90-0.66*mcs
#Interpretation: for each unit increase in mcs, cesd decreases by 0.66
```

3. How much variability in the `cesd` does the `mcs` explain? (what is the R<sup>2</sup>?) Write a sentence describing how well the `mcs` does in predicting the `cesd`.
```{r}
#R-squared=0.465 indicating that the predictor(mcs) explains 46.5% variability in the outcome(cesd)
```

4. [Model 2] Run a second linear regression model (`lm()`) for the `cesd` putting in all of the other variables: 
    + `age`
    + `female`
    + `pss_fr`
    + `homeless`
    + `pcs`
    + `mcs`
    
    + Print out the model results with the coefficients and tests and model fit statistics.
    
```{r}
#linear regression for cesd and all other variables
Model2 <- lm(cesd~age + female + pss_fr + homeless + pcs + mcs, data=h1)
summary(Model2)
```

5. Which variables are significant in the model? Write a sentence or two describing the impact of these variables for predicting depression scores (HINT: interpret the coefficient terms).

```{r}
#Female, pss_fr, pcs and mcs are significant

#R-squared is 0.5249 indicating that 52.49% of the variabilty in average cesd is due to the independent variables in the model

#From this output we can see that:
#Being female increases the cesd by 2.35, holding all other variables constant
#If pss_fr increases by one unit, the cesd decreases by 0.26 units, holding all other variables constant.
#If pcs increases by one unit, then the cesd decreases by 0.24 units, holding all other variables constant.
##If mcs increases by one unit, then the cesd decreases by 0.62 units, holding all other variables constant.
```

6. Following the example we did in class for the Prestige dataset [https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true](https://cdn.rawgit.com/vhertzb/2018week9/2f2ea142/2018week9.html?raw=true), generate the diagnostic plotss for this model with these 6 predictors (e.g. get the residual plot by variables, the added-variable plots, the Q-Q plot, diagnostic plots). Also run the VIFs to check for multicollinearity issues.

```{r}
library(car)
#residual plot
residualPlots(Model2)
```

```{r}
#added variable plots
avPlots(Model2)
```

```{r}
#qq plot
qqPlot(Model2)
```

```{r}
#run Bonferroni test for outliers
outlierTest(Model2)
```

```{r}
#identify highly influential points
influenceIndexPlot(Model2)
```

```{r}
#Influence plot
influencePlot(Model2)
```

7. [Model 3] Repeat Model 1 above, except this time run a logistic regression (`glm()`) to predict CESD scores => 16 (using the `cesd_gte16` as the outcome) as a function of `mcs` scores. Show a summary of the sfinal fitted model and explain the coefficients. [**REMEMBER** to compute the Odds Ratios after you get the raw coefficient (betas)].

```{r}
#logistic regression using cesd_gte16 as outcome
Model3 <- glm(cesd_gte16~mcs, data=h1, family=binomial)
```

```{r}
# look at the model results
Model3
```

```{r}
# summary of the model results
summary(Model3)
```

```{r}
# coefficients of the model - these are the
# RAW Betas 
coef(Model3)
```

```{r}
#take the exp to get the odds ratios
exp(coef(Model3))
```

```{r}
#Interpretation: for each unit increase in mcs, cesd decreases by 0.17
```
8. Use the `predict()` function like we did in class to predict CESD => 16 and compare it back to the original data. For now, use a cutoff probability of 0.5 - if the probability is > 0.5 consider this to be true and false otherwise. Like we did in class. **REMEMBER** See the R code for the class example at [https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R](https://github.com/melindahiggins2000/N741_lecture11_27March2018/blob/master/lesson11_logreg_Rcode.R)
    + How well did the model correctly predict CESD scores => 16 (indicating depression)? (make the "confusion matrix" and look at the true positives and true negatives versus the false positives and false negatives).

```{r}
# look at the predicted probabilities
Model3.predict <- predict(Model3, newdata=h1,
                      type="response")
```


```{r}
# Look at the tradeoffs for at threshold
# of 0.5
# confusion matrix
table(h1$cesd_gte16, Model3.predict > 0.5)
```
```{r}
#The model did a good job of predicting CESD scores => 16. It correclty predicted 395 of all the true cases
```
9. Make an ROC curve plot and compute the AUC and explain if this is a good model for predicting depression or not

```{r}
#ROC curve plot
library(ROCR)
p <- predict(Model3, newdata=h1, 
             type="response")
pr <- prediction(p, as.numeric(h1$cesd_gte16))
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
abline(a=0, b=1, col="red")
```

```{r}
#Compute AUC
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

```{r}
# The AUC is 0.922 indicating that this model is great for predicting depression
```
10. Make a plot showing the probability curve - put the `mcs` values on the X-axis and the probability of depression on the Y-axis. Based on this plot, do you think the `mcs` is a good predictor of depression? [**FYI** This plot is also called an "effect plot" is you're using `Rcmdr` to do these analyses.]

```{r}
# plot the continuous predictor
# for these predicted probabilities
plot(h1$mcs, Model3.predict)
```

```{r}
#Based on this plot, it does appear that mcs is a good predictor of depression.
```

---

The github repository for this assignment can be accessed via this link (https://github.com/RosemaryKinuthia/N741Spring2018_Homework6.git)[https://github.com/RosemaryKinuthia/N741Spring2018_Homework6.git]
---


